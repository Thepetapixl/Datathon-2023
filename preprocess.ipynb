{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "N = 0\n",
    "corpusroot = './Datathon-2023/'\n",
    "docs = {}\n",
    "for filename in os.listdir(corpusroot):\n",
    "    if filename.startswith('0') or filename.startswith('1'):\n",
    "        with open(os.path.join(corpusroot, filename), \"r\", encoding = 'utf-8') as doc:\n",
    "            docs[filename] = doc.read()\n",
    "            N += 1\n",
    "\n",
    "# tokenize and stem the documents\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "stemmer = PorterStemmer()\n",
    "doc_tokens = {}\n",
    "\n",
    "for filename, doc in docs.items():\n",
    "    tokens = [stemmer.stem(token.lower()) for token in tokenizer.tokenize(\n",
    "        doc) if token.lower() not in stop_words]\n",
    "    doc_tokens[filename] = tokens\n",
    "\n",
    "idf = {}\n",
    "for token in set([token for tokens in doc_tokens.values() for token in tokens]):\n",
    "    df = sum([1 for tokens in doc_tokens.values() if token in tokens])\n",
    "    idf[token] = math.log10(N / df)\n",
    "\n",
    "# compute the lnc.ltc weights\n",
    "def calculate_weights(flag):\n",
    "    doc_weights = {}\n",
    "    for filename, tokens in doc_tokens.items():\n",
    "        tf = {}\n",
    "        for token in tokens: # for each file counting the occurances of the token i.e. tf_raw\n",
    "            if token in tf: \n",
    "                tf[token] += 1 # stores tf_raw for each token in the document \n",
    "            else:\n",
    "                tf[token] = 1\n",
    "\n",
    "        doc_weights[filename] = {}\n",
    "        for token, freq in tf.items():\n",
    "            \n",
    "            # if token in idf:\n",
    "                weight = (1 + math.log10(freq))\n",
    "                if (flag==True):\n",
    "                    doc_weights[filename][token] = weight * idf[token]\n",
    "                else:\n",
    "                    doc_weights[filename][token] = weight \n",
    "    return doc_weights\n",
    "\n",
    "\n",
    "def query(qstring):\n",
    "    # Tokenize and stem query\n",
    "    tokens = [stemmer.stem(token.lower()) for token in tokenizer.tokenize(qstring) if token.lower() not in stop_words]\n",
    "    \n",
    "    # Calculate query weights - logtf of query tokens \n",
    "    query_weights = {}\n",
    "    for token in tokens:\n",
    "        if token not in query_weights:\n",
    "            temp = tokens.count(token)\n",
    "            if temp == 0:\n",
    "                query_weights[token] = 1\n",
    "            else:\n",
    "                query_weights[token] = (1 + math.log10(temp))\n",
    "\n",
    "    # Initialize document values\n",
    "    values = {filename: 0 for filename in docs}\n",
    "    \n",
    "    query_tf_idf = {}\n",
    "    \n",
    "    # Calculate idf query term\n",
    "    for token, weight in query_weights.items():\n",
    "        query_idf = getidf(token)\n",
    "        if query_idf == -1:\n",
    "            query_idf = 0\n",
    "        query_tf_idf[token] = weight * query_idf\n",
    "\n",
    "    # Query magnitude\n",
    "    query_mag = sum([weight*weight for weight in query_tf_idf.values() if weight != 0])\n",
    "    query_mag = math.sqrt(query_mag)\n",
    "\n",
    "    # Normalised Query vectors\n",
    "    for val in query_tf_idf:\n",
    "        query_tf_idf[val] = query_tf_idf[val] / query_mag\n",
    "    \n",
    "    # Document magnitude    \n",
    "    doc_mag = {}\n",
    "    doc_weights = calculate_weights(False)\n",
    "    for doc in doc_weights:\n",
    "        x = sum([weight*weight for weight in doc_weights[doc].values() if weight != 0])\n",
    "        doc_mag[doc] = math.sqrt(x)\n",
    "\n",
    "    #Normalised Document vectors\n",
    "    for doc,vals in doc_weights.items():\n",
    "        mag_doc = doc_mag[doc]\n",
    "        for t,v in vals.items():\n",
    "            x = v / mag_doc\n",
    "            doc_weights[doc][t] = x\n",
    "     \n",
    "    result = {}     \n",
    "    for filename in doc_weights:\n",
    "        for token in query_tf_idf:\n",
    "            if token in doc_weights[filename]:\n",
    "                values[filename] += doc_weights[filename][token] * query_tf_idf[token]\n",
    "        result[filename] = values\n",
    "\n",
    "    sorted_values = sorted(values.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    return sorted_values[0][0], sorted_values[0][1]\n",
    "\n",
    "def getidf(token):\n",
    "    if token in idf:\n",
    "        return idf[token]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def getweight(filename, token):\n",
    "    token = stemmer.stem(token.lower())\n",
    "    doc_weights = calculate_weights(True)\n",
    "    if token in doc_weights[filename]:\n",
    "        return doc_weights[filename][token]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "print(\"%.12f\" % getidf('british'))\n",
    "print(\"%.12f\" % getidf('union'))\n",
    "print(\"%.12f\" % getidf('war'))\n",
    "print(\"%.12f\" % getidf('power'))\n",
    "print(\"%.12f\" % getidf('great'))\n",
    "print(\"--------------\")\n",
    "print(\"%.12f\" % getweight('02_washington_1793.txt', 'arrive'))\n",
    "print(\"%.12f\" % getweight('07_madison_1813.txt', 'war'))\n",
    "print(\"%.12f\" % getweight('12_jackson_1833.txt', 'union'))\n",
    "print(\"%.12f\" % getweight('09_monroe_1821.txt', 'great'))\n",
    "print(\"%.12f\" % getweight('05_jefferson_1805.txt', 'public'))\n",
    "print(\"--------------\")\n",
    "print(\"(%s, %.12f)\" % query(\"pleasing people\"))\n",
    "print(\"(%s, %.12f)\" % query(\"british war\"))\n",
    "print(\"(%s, %.12f)\" % query(\"false public\"))\n",
    "print(\"(%s, %.12f)\" % query(\"people institutions\"))\n",
    "print(\"(%s, %.12f)\" % query(\"violated willingly\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
